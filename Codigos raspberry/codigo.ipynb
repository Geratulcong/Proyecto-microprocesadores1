{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f46615",
   "metadata": {},
   "source": [
    "# Notebook: Visualización de distribución por clases y construcción de una CNN\n",
    "# Autor: generado automáticamente\n",
    "# Objetivo: cargar 'datos_sisfall_completo.csv', mostrar distribución por clases, preparar ventanas (WINDOW=10, 6 features), definir/entrenar/guardar una CNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q pandas numpy matplotlib seaborn scikit-learn tensorflow joblib\n",
    "# Si ya tienes estas librerías puedes comentar la línea anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b069bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Importar librerías y mostrar versiones\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "print('tensorflow', tf.__version__)\n",
    "\n",
    "# GPU/Device info (si aplica)\n",
    "try:\n",
    "    devices = tf.config.list_physical_devices()\n",
    "    print('Devices:', devices)\n",
    "except Exception as e:\n",
    "    print('No se pudo listar dispositivos:', e)\n",
    "\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ddd0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Cargar y explorar dataset\n",
    "csv_path = Path('Codigos raspberry') / 'datos_sisfall_completo.csv'\n",
    "print('Buscando CSV en:', csv_path)\n",
    "\n",
    "if not csv_path.exists():\n",
    "    print('Archivo no encontrado:', csv_path)\n",
    "else:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    display(df.head())\n",
    "    print('\\nInfo:')\n",
    "    print(df.info())\n",
    "    if 'state' in df.columns:\n",
    "        counts = df['state'].value_counts().sort_index()\n",
    "        print('\\nDistribución por estado (conteos):')\n",
    "        print(counts)\n",
    "        pct = (counts / counts.sum() * 100).round(2)\n",
    "        print('\\nPorcentajes:')\n",
    "        print(pct)\n",
    "        fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "        sns.barplot(x=counts.index.astype(str), y=counts.values, ax=ax[0])\n",
    "        ax[0].set_title('Distribución por clase (conteos)')\n",
    "        ax[0].set_xlabel('state')\n",
    "        ax[0].set_ylabel('conteos')\n",
    "        ax[1].pie(counts.values, labels=counts.index.astype(str), autopct='%1.1f%%')\n",
    "        ax[1].set_title('Distribución por clase (porcentaje)')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"La columna 'state' no existe en el CSV. Revisar el archivo de entrada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48357237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Preparar ventanas deslizantes (WINDOW_SIZE=10) y features\n",
    "FEATURES = ['ax','ay','az','gx','gy','gz']\n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "assert 'df' in globals(), \"Ejecuta la celda de carga de dataset primero.\" \n",
    "\n",
    "# Función para crear ventanas agrupando por columna 'file' si existe, si no crear una única secuencia\n",
    "def create_windows(df, features, window_size, group_col_candidates=('file','file_name','sequence','trial')):\n",
    "    groups = None\n",
    "    for c in group_col_candidates:\n",
    "        if c in df.columns:\n",
    "            groups = [g for _, g in df.groupby(c)]\n",
    "            print(f'Agrupando por columna: {c}')\n",
    "            break\n",
    "    if groups is None:\n",
    "        groups = [df]\n",
    "        print('No hay columna de agrupación, procesando dataset como secuencia única')\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for g in groups:\n",
    "        # asegurarnos de ordenar por índice si procede\n",
    "        g = g.reset_index(drop=True)\n",
    "        n = len(g)\n",
    "        if n < window_size:\n",
    "            continue\n",
    "        for i in range(n - window_size + 1):\n",
    "            win = g.loc[i:i+window_size-1, features]\n",
    "            if win.isnull().any().any():\n",
    "                continue\n",
    "            X_list.append(win.values.astype(np.float32))\n",
    "            # etiqueta: moda de 'state' en la ventana\n",
    "            if 'state' in g.columns:\n",
    "                mode = g.loc[i:i+window_size-1, 'state'].mode()\n",
    "                label = mode.iloc[0] if len(mode)>0 else g.loc[i, 'state']\n",
    "            else:\n",
    "                label = 0\n",
    "            y_list.append(int(label))\n",
    "    X = np.array(X_list)\n",
    "    y = np.array(y_list)\n",
    "    return X, y\n",
    "\n",
    "X, y = create_windows(df, FEATURES, WINDOW_SIZE)\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)\n",
    "\n",
    "if y.size>0:\n",
    "    import pandas as _pd\n",
    "    print('\\nDistribución de etiquetas tras windowing:')\n",
    "    print(_pd.Series(y).value_counts().sort_index())\n",
    "    fig, ax = plt.subplots(figsize=(6,3))\n",
    "    sns.countplot(x=y, ax=ax)\n",
    "    ax.set_title('Etiquetas por ventana')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No se generaron ventanas. Revisa el CSV y las columnas de features/state.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836587a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Normalizar (StandardScaler) y guardar scaler\n",
    "if X.size>0:\n",
    "    n_windows, w, n_features = X.shape\n",
    "    X_reshaped = X.reshape(-1, n_features)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled_flat = scaler.fit_transform(X_reshaped)\n",
    "    X_scaled = X_scaled_flat.reshape(n_windows, w, n_features)\n",
    "    # guardar scaler\n",
    "    scaler_path = Path('Codigos raspberry') / 'scaler.save'\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print('Scaler guardado en', scaler_path)\n",
    "    X = X_scaled\n",
    "else:\n",
    "    print('Nada que normalizar (X vacío)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da7a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Train/Test split\n",
    "if X.size>0:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
    "else:\n",
    "    print('No hay datos para split')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Definir arquitectura CNN\n",
    "if X.size>0:\n",
    "    n_classes = len(np.unique(y))\n",
    "    input_shape = (WINDOW_SIZE, len(FEATURES))\n",
    "    def build_model(input_shape, n_classes):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv1D(32, 3, activation='relu', input_shape=input_shape))\n",
    "        model.add(layers.MaxPooling1D(2))\n",
    "        model.add(layers.Conv1D(64, 3, activation='relu'))\n",
    "        model.add(layers.MaxPooling1D(2))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dropout(0.3))\n",
    "        model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "        return model\n",
    "\n",
    "    model = build_model(input_shape, n_classes)\n",
    "    model.summary()\n",
    "else:\n",
    "    print('No hay datos para construir el modelo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1874a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Compilar y entrenar (o cargar si existe el modelo)\n",
    "model_path = Path('Codigos raspberry') / 'modelo_cnn_imu.h5'\n",
    "\n",
    "if X.size>0:\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    if model_path.exists():\n",
    "        print('Cargando modelo existente:', model_path)\n",
    "        model = keras.models.load_model(model_path)\n",
    "    else:\n",
    "        callbacks = [keras.callbacks.ModelCheckpoint(model_path, save_best_only=True, monitor='val_loss')]\n",
    "        history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1, callbacks=callbacks)\n",
    "        # plot history\n",
    "        fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "        ax[0].plot(history.history['loss'], label='train_loss')\n",
    "        ax[0].plot(history.history['val_loss'], label='val_loss')\n",
    "        ax[0].legend(); ax[0].set_title('Loss')\n",
    "        ax[1].plot(history.history['accuracy'], label='train_acc')\n",
    "        ax[1].plot(history.history['val_accuracy'], label='val_acc')\n",
    "        ax[1].legend(); ax[1].set_title('Accuracy')\n",
    "        plt.show()\n",
    "else:\n",
    "    print('No se puede entrenar: X vacío')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2487ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Evaluación en test set\n",
    "if X.size>0:\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Test loss: {loss:.4f}  Test acc: {acc:.4f}')\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    print('\\nClassification report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_title('Matriz de confusión')\n",
    "    ax.set_xlabel('Predicted'); ax.set_ylabel('True')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No hay datos para evaluar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167491d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Prueba de predicción sobre una ventana de test\n",
    "if X.size>0:\n",
    "    LABELS = None\n",
    "    try:\n",
    "        # si las etiquetas son 4/5 etc., permitir mapear manualmente\n",
    "        LABELS = ['pararse','sentarse','caminar','caerse','quieto'][:len(np.unique(y))]\n",
    "    except Exception:\n",
    "        LABELS = [str(i) for i in sorted(np.unique(y))]\n",
    "\n",
    "    idx = 0\n",
    "    sample = X_test[idx:idx+1]\n",
    "    probs = model.predict(sample)[0]\n",
    "    pred = np.argmax(probs)\n",
    "    print('Predicted:', pred, 'label:', LABELS[pred] if pred < len(LABELS) else pred)\n",
    "    print('Probabilidades:', probs)\n",
    "else:\n",
    "    print('No hay muestra para predecir')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea3a96",
   "metadata": {},
   "source": [
    "# 10) Notas finales y siguientes pasos\n",
    "\n",
    "# Siguientes pasos recomendados:\n",
    "# - Aumentar epochs y ajustar batch_size si tienes suficiente CPU/RAM.\n",
    "# - Guardar y reutilizar el scaler en el cliente real (`conexcion.py`) para normalizar en producción.\n",
    "# - Si la clase 'quieto' u otras están desbalanceadas, considerar técnicas de balanceo (SMOTE, oversampling o ponderar la pérdida).\n",
    "# - Validar el modelo en datos reales del Arduino (usando el pipeline de BLE -> `conexcion.py`).\n",
    "\n",
    "print('Notebook listo. Ejecuta celdas en orden: instalar dependencias -> carga CSV -> crear ventanas -> entrenar/evaluar.')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
