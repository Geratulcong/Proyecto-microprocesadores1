"""
Script para entrenar CNN 1D con datos capturados del Arduino
Lee archivos limpios, crea ventanas y entrena modelo
"""
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Flatten, Dense
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import seaborn as sns

# --- CONFIGURACIÃ“N ---
DATOS_DIR = Path(__file__).parent / "datos_limpios"
WINDOW_SIZE = 40  # 40 muestras = 2 segundos a 20Hz
OVERLAP = 20  # Solapamiento de ventanas (50%)
TEST_SIZE = 0.2
EPOCHS = 50
BATCH_SIZE = 16

print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
print("â•‘   Entrenamiento CNN para detecciÃ³n de caÃ­das  â•‘")
print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

# --- 1. CARGAR DATOS ---
print("ðŸ“‚ Buscando archivos en:", DATOS_DIR)

if not DATOS_DIR.exists():
    print(f"âŒ Error: Ejecuta primero 'limpiar_datos.py'")
    exit(1)

# Buscar archivos CSV
archivos_csv = list(DATOS_DIR.glob("*.csv"))
archivos_txt = list(DATOS_DIR.glob("*.txt"))
archivos = archivos_csv if archivos_csv else archivos_txt

if not archivos:
    print(f"âŒ No se encontraron archivos .csv o .txt en '{DATOS_DIR}'")
    exit(1)

print(f"ðŸ“„ Archivos encontrados: {len(archivos)}\n")

# Clasificar archivos automÃ¡ticamente segÃºn su nombre
datos_totales = []
etiquetas_totales = []

for archivo in archivos:
    print(f"ðŸ“„ {archivo.name}")
    
    # Detectar automÃ¡ticamente si es caÃ­da o normal por el nombre
    nombre_lower = archivo.name.lower()
    if 'caida' in nombre_lower or 'fall' in nombre_lower:
        etiqueta = 1
        tipo = "CAÃDA"
    elif 'normal' in nombre_lower or 'adl' in nombre_lower:
        etiqueta = 0
        tipo = "NORMAL"
    else:
        # Si no se detecta automÃ¡ticamente, preguntar
        while True:
            resp = input("   Etiqueta (0=normal, 1=caÃ­da): ").strip()
            if resp in ['0', '1']:
                etiqueta = int(resp)
                tipo = "NORMAL" if etiqueta == 0 else "CAÃDA"
                break
            print("   âŒ Valor invÃ¡lido. Usa 0 o 1")
    
    print(f"   ðŸ·ï¸  Clasificado como: {tipo}")
    
    # Cargar archivo
    try:
        df = pd.read_csv(archivo)
        
        # Detectar columnas disponibles
        columnas = df.columns.tolist()
        
        # Seleccionar columnas segÃºn lo disponible
        if 'cadera_ax' in columnas and 'pierna_ax' in columnas:
            # Usar datos de AMBOS sensores (12 features)
            cols = [
                'cadera_ax', 'cadera_ay', 'cadera_az', 'cadera_gx', 'cadera_gy', 'cadera_gz',
                'pierna_ax', 'pierna_ay', 'pierna_az', 'pierna_gx', 'pierna_gy', 'pierna_gz'
            ]
            print(f"   ðŸ“ Usando datos de CADERA + PIERNA (12 features)")
        elif 'cadera_ax' in columnas:
            # Usar solo datos de la cadera
            cols = ['cadera_ax', 'cadera_ay', 'cadera_az', 'cadera_gx', 'cadera_gy', 'cadera_gz']
            print(f"   ðŸ“ Usando datos del sensor de CADERA (6 features)")
        elif 'ax' in columnas:
            # Usar datos directos
            cols = ['ax', 'ay', 'az', 'gx', 'gy', 'gz']
            print(f"   ðŸ“ Usando datos del sensor Ãºnico (6 features)")
        else:
            print(f"   âŒ Error: Columnas no reconocidas: {columnas}")
            continue
        
        print(f"   âœ… Cargado: {len(df)} muestras")
        
        # Escalar giroscopio x4 para darle mÃ¡s peso
        cols_giro = [c for c in cols if 'gx' in c or 'gy' in c or 'gz' in c]
        if cols_giro:
            df[cols_giro] = df[cols_giro] * 4.0
            print(f"   âš™ï¸  Giroscopio escalado x4: {cols_giro}")
        
        # Crear ventanas con solapamiento
        ventanas_creadas = 0
        for i in range(0, len(df) - WINDOW_SIZE + 1, OVERLAP):
            ventana = df.iloc[i:i+WINDOW_SIZE][cols].values
            datos_totales.append(ventana)
            etiquetas_totales.append(etiqueta)
            ventanas_creadas += 1
        
        print(f"   ðŸ“Š Ventanas creadas: {ventanas_creadas}\n")
    
    except Exception as e:
        print(f"   âŒ Error: {e}\n")

# Convertir a arrays
X = np.array(datos_totales, dtype=np.float32)
y = np.array(etiquetas_totales, dtype=np.int32)

print(f"\nðŸ“Š Datos preparados:")
print(f"   Total de ventanas: {len(X)}")
print(f"   Forma de X: {X.shape}")
print(f"   DistribuciÃ³n de clases:")
unique, counts = np.unique(y, return_counts=True)
for clase, count in zip(unique, counts):
    nombre = "Normal" if clase == 0 else "CaÃ­da"
    print(f"      {nombre}: {count} ventanas ({count/len(y)*100:.1f}%)")

# --- 2. TRAIN/TEST SPLIT ---
print(f"\nâœ‚ï¸ Dividiendo datos (test={TEST_SIZE*100:.0f}%)...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=TEST_SIZE, random_state=42, stratify=y
)
print(f"   Train: {len(X_train)} ventanas")
print(f"   Test: {len(X_test)} ventanas")

# --- 3. CREAR MODELO CNN SIMPLIFICADO ---
# Detectar nÃºmero de features automÃ¡ticamente
num_features = X.shape[2]  # Puede ser 6 o 12
print(f"\nðŸ§  Creando modelo CNN 1D para {num_features} features...")
print("   Modelo simplificado (menos parÃ¡metros, mÃ¡s regularizaciÃ³n)\n")

model = Sequential([
    # Una sola capa convolucional mÃ¡s simple
    Conv1D(16, kernel_size=3, activation='relu', input_shape=(WINDOW_SIZE, num_features)),
    MaxPooling1D(2),
    Dropout(0.5),  # Mayor dropout para prevenir overfitting
    
    # Capa densa mÃ¡s pequeÃ±a
    Flatten(),
    Dense(32, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')  # Binario: 0=normal, 1=caÃ­da
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# --- 4. ENTRENAR ---
print("\nðŸš€ Entrenando modelo...")
print("ðŸ’¡ Modelo simplificado para reducir overfitting:")
print("   - Solo 1 capa Conv1D (en vez de 2)")
print("   - 16 filtros (en vez de 32+64)")
print("   - Dense de 32 neuronas (en vez de 64)")
print("   - Dropout aumentado a 0.5\n")

early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)

history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=[early_stop],
    verbose=1
)

# --- 5. EVALUAR ---
print("\nðŸ“ˆ Evaluando modelo...")
loss, acc = model.evaluate(X_test, y_test)
print(f"\nâœ… PÃ©rdida: {loss:.4f} | PrecisiÃ³n: {acc:.4f}")

# Predicciones
y_pred = (model.predict(X_test) > 0.5).astype(int)

# Matriz de confusiÃ³n
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Normal', 'CaÃ­da'],
            yticklabels=['Normal', 'CaÃ­da'])
plt.xlabel("PredicciÃ³n")
plt.ylabel("Real")
plt.title("Matriz de ConfusiÃ³n")
plt.tight_layout()
plt.savefig('matriz_confusion_arduino.png', dpi=150)
print("ðŸ’¾ Matriz guardada: matriz_confusion_arduino.png")

# Reporte
print("\nðŸ“‹ Reporte de clasificaciÃ³n:")
print(classification_report(y_test, y_pred, target_names=['Normal', 'CaÃ­da']))

# --- 6. GUARDAR MODELO ---
MODEL_PATH = "modelo_caidas_arduino.h5"
model.save(MODEL_PATH)
print(f"\nðŸ’¾ Modelo guardado: {MODEL_PATH}")

# GrÃ¡fico de entrenamiento
plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Val')
plt.title('PÃ©rdida')
plt.xlabel('Ã‰poca')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Val')
plt.title('PrecisiÃ³n')
plt.xlabel('Ã‰poca')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.savefig('entrenamiento_arduino.png', dpi=150)
print(f"ðŸ’¾ GrÃ¡fico guardado: entrenamiento_arduino.png")

print("\nâœ… Â¡Entrenamiento completado!")
